{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joyce-ZhouY/ECE1512-ProjectA/blob/main/Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-dZAQIpOmux"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Union\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and process data**"
      ],
      "metadata": {
        "id": "NJzfW5gPPsOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/images.zip"
      ],
      "metadata": {
        "id": "FzbXtW64m-1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mkdir\n",
        "path_train = '/content/train'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_train\n",
        ")\n",
        "\n",
        "path_test = '/content/test'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_test\n",
        ")\n",
        "\n",
        "path_train_HP = '/content/train/HP'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_train_HP\n",
        ")\n",
        "\n",
        "path_train_SSA = '/content/train/SSA'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_train_SSA\n",
        ")\n",
        "\n",
        "path_test_HP = '/content/test/HP'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_test_HP\n",
        ")\n",
        "\n",
        "path_test_SSA = '/content/test/SSA'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_test_SSA\n",
        ")\n",
        "\n",
        "path_train_aug = '/content/train_aug'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_train_aug\n",
        ")\n",
        "\n",
        "path_train_HP_aug = '/content/train_aug/HP'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_train_HP_aug\n",
        ")\n",
        "\n",
        "path_train_SSA_aug = '/content/train_aug/SSA'\n",
        "tf.io.gfile.mkdir(\n",
        "    path_train_SSA_aug\n",
        ")"
      ],
      "metadata": {
        "id": "TQ6hXJmBZR24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Augmentation**"
      ],
      "metadata": {
        "id": "fXp_bfM3NPAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/annotations.csv'\n",
        "df = pd.read_csv(path)\n",
        "csv = dict(df)\n",
        "image_num = len(csv.get('Image Name'))\n",
        "\n",
        "# print(csv.get('Image Name')[0])\n",
        "\n",
        "for i in range(image_num):\n",
        "  if csv.get('Partition')[i] == \"train\":\n",
        "    if csv.get('Majority Vote Label')[i] == \"HP\":\n",
        "      src = '/content/images/' + csv.get('Image Name')[i]\n",
        "      dst = '/content/train/HP/' + csv.get('Image Name')[i]\n",
        "      tf.io.gfile.copy(src, dst, overwrite=True)\n",
        "    else:\n",
        "      src = '/content/images/' + csv.get('Image Name')[i]\n",
        "      dst = '/content/train/SSA/' + csv.get('Image Name')[i]\n",
        "      tf.io.gfile.copy(src, dst, overwrite=True)\n",
        "  else:\n",
        "    if csv.get('Majority Vote Label')[i] == \"HP\":\n",
        "      src = '/content/images/' + csv.get('Image Name')[i]\n",
        "      dst = '/content/test/HP/' + csv.get('Image Name')[i]\n",
        "      tf.io.gfile.copy(src, dst, overwrite=True)\n",
        "    else:\n",
        "      src = '/content/images/' + csv.get('Image Name')[i]\n",
        "      dst = '/content/test/SSA/' + csv.get('Image Name')[i]\n",
        "      tf.io.gfile.copy(src, dst, overwrite=True)"
      ],
      "metadata": {
        "id": "UntE85NhZ3a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib. image as image\n",
        "from matplotlib import pyplot as plt\n",
        "from random import random\n",
        "\n",
        "path = '/content/annotations.csv'\n",
        "df = pd.read_csv(path)\n",
        "csv = dict(df)\n",
        "image_num = len(csv.get('Image Name'))\n",
        "#print(\"num=\",image_num)\n",
        "\n",
        "for i in range(image_num):\n",
        "    if csv.get('Majority Vote Label')[i] == \"HP\":\n",
        "      src = '/content/images/' + csv.get('Image Name')[i]\n",
        "      img=image.imread(src)\n",
        "      img_aug = tf.image.rot90(tf.image.random_flip_up_down(img),k=round(random()*3))+tf.random.normal(shape=[224,224,3], mean=0.0, stddev=0.1,dtype=tf.float32)\n",
        "      tf.keras.utils.save_img('/content/train_aug/HP/'+ csv.get('Image Name')[i], img_aug, data_format=None, file_format=None, scale=True)\n",
        "    else:\n",
        "      src = '/content/images/' + csv.get('Image Name')[i]\n",
        "      img=image.imread(src)\n",
        "      img_aug = tf.image.rot90(tf.image.random_flip_up_down(img),k=round(random()*3))+tf.random.normal(shape=[224,224,3], mean=0.0, stddev=0.1,dtype=tf.float32)\n",
        "      tf.keras.utils.save_img('/content/train_aug/SSA/'+ csv.get('Image Name')[i], img_aug, data_format=None, file_format=None, scale=True)\n",
        "      #break"
      ],
      "metadata": {
        "id": "JSOA2qDONcDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224,224)\n",
        "# train_dir = '/content/train'\n",
        "train_dir = '/content/train_aug'\n",
        "BATCH_SIZE=32\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE)\n",
        "\n",
        "test_dir = '/content/test' \n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE)"
      ],
      "metadata": {
        "id": "9W01jg8Uixa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(lambda x, y: (tf.cast(x, tf.float32), tf.one_hot(y, 2)))\n",
        "test_dataset = test_dataset.map(lambda x, y: (tf.cast(x, tf.float32), tf.one_hot(y, 2)))"
      ],
      "metadata": {
        "id": "G9rY_bxobnXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Accuracy matrix**"
      ],
      "metadata": {
        "id": "1TH3lTfGP3VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def f1(tp,tn,fp):\n",
        "    precision=tp/(tp+tn+K.epsilon())\n",
        "    recall=tp/(tp+fp+K.epsilon())\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "igLHRqpir_E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ALPHA = 0.5\n",
        "TEMPERATURE = 4\n",
        "\n",
        "\n",
        "# loss = ALPHA * student_hard_target + (1-ALPHA) * KLDivergence(teacher_soft_target, student_soft_target)\n",
        "\n",
        "def compute_teacher_loss(images, labels):\n",
        "  subclass_logits = teacher_model(images, training=True)\n",
        "  cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=subclass_logits)\n",
        "  return cross_entropy_loss_value\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  soft_targets = tf.nn.softmax(teacher_logits / temperature)\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "  student_subclass_logits = student_model(images, training=True)\n",
        "  teacher_subclass_logits = teacher_model(images, training=False)\n",
        "  distillation_loss_value = distillation_loss(teacher_subclass_logits,student_subclass_logits,DISTILLATION_TEMPERATURE)\n",
        "  cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels, student_subclass_logits)\n",
        "  loss= ALPHA*distillation_loss_value + (1-ALPHA)* cross_entropy_loss_value\n",
        "  return loss\n",
        "def compute_student_noKD_loss(images, labels):\n",
        "  subclass_logits = student_no_distillation(images, training=True)\n",
        "  cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=subclass_logits)\n",
        "  return cross_entropy_loss_value\n",
        "\n",
        "def compute_student_loss_withoutKD(images, labels):\n",
        "  subclass_logits = student_model(images, training=True)\n",
        "  cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=subclass_logits)\n",
        "  return cross_entropy_loss_value\n",
        "\n",
        "def compute_confusion_matrix(model, images, labels):\n",
        "  y_prediction = model(images, training=False)\n",
        "  y_prediction = np.argmax (y_prediction, axis = 1)\n",
        "  y_true=np.argmax(labels, axis=1)\n",
        "\n",
        "  result = confusion_matrix(y_true, y_prediction)\n",
        "  return result\n",
        "\n",
        "\n",
        "def compute_num_correct(model, images, labels):\n",
        "  class_logits = model(images, training=False)\n",
        "  value= tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
        "  return value\n",
        "\n",
        "def train_and_evaluate(model, compute_loss_fn):\n",
        "  # optimizer = tf.optimizers.Adam(learning_rate=1e-3)\n",
        "  time_matrix=[]\n",
        "  matrix_1 = []\n",
        "  matrix_2 = []\n",
        "  for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Run training.\n",
        "    start_time = time.time()\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    for images, labels in train_dataset:\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    con_matrix=[[0,0],[0,0]]\n",
        "    for images, labels in test_dataset:\n",
        "      acc = compute_confusion_matrix(model, images, labels)\n",
        "      con_matrix[0][0] += acc[0][0]\n",
        "      con_matrix[0][1] += acc[0][1]\n",
        "      con_matrix[1][0] += acc[1][0]\n",
        "      con_matrix[1][1] += acc[1][1]\n",
        "      print(con_matrix)\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    time_matrix.append(epoch_time)\n",
        "    print(\"Total time per epoch: {0:.2f} seconds\".format(epoch_time))\n",
        "\n",
        "    con_matrix = np.asarray(con_matrix)\n",
        "    f1_1 = f1(con_matrix[0][0], con_matrix[0][1], con_matrix[1,0])\n",
        "    f1_2 = f1(con_matrix[1][1], con_matrix[0][1], con_matrix[1,0])\n",
        "    print(f1_1)\n",
        "    print(f1_2)\n",
        "    matrix_1.append(f1_1)\n",
        "    matrix_2.append(f1_2)\n",
        "  total_time = np.sum(time_matrix)\n",
        "  print(\"Total time of training this model: {0:.2f} seconds\".format(total_time))\n",
        "  \n",
        "  return matrix_1, matrix_2\n"
      ],
      "metadata": {
        "id": "XR0lms-Lemac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Teacher Model\n",
        "# -- use pre-trained ResNet50V2"
      ],
      "metadata": {
        "id": "PRKVtwUgN1X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained model -- Techer\n",
        "# Create base model\n",
        "teacher_resnet_50 = tf.keras.applications.resnet_v2.ResNet50V2(include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze base model\n",
        "teacher_resnet_50.trainable=False\n",
        "\n",
        "# Create new model on top.\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = teacher_resnet_50(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(dtype='float32')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = tf.keras.layers.Dense(2)(x)\n",
        "teacher_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "initial_epoch = 10\n",
        "teacher_model.compile(optimizer=optimizer\n",
        ")\n",
        "                      \n",
        "\n",
        "                   \n",
        "teacher_model.summary()\n"
      ],
      "metadata": {
        "id": "fakyTTbxlmll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Teacher Model"
      ],
      "metadata": {
        "id": "c5T9BIp9N99w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = initial_epoch\n",
        "\n",
        "h1, h2 = train_and_evaluate(teacher_model, compute_teacher_loss)"
      ],
      "metadata": {
        "id": "BZqhGtbbSjgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_1 = h1 #Accuracy\n",
        "f1_2 = h2\n",
        "\n",
        "\n",
        "print(f1_1)\n",
        "print(f1_2)\n"
      ],
      "metadata": {
        "id": "olm8KK1TJ7Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "# plt.subplot(2, 1, 1)\n",
        "plt.plot(f1_1, label='F1 Score: HP',linestyle='--', marker='o')\n",
        "plt.plot(f1_2, label='F1 Score: SSA',linestyle='--', marker='o')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Testing Accuracy of Teacher Model')\n",
        "\n",
        "\n",
        "# plt.savefig('/content/images_mhist/teacher_train_acc.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7lVKMO3DmYz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tune teacher model and re-train"
      ],
      "metadata": {
        "id": "kZSiKbNtOB3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze the final set of CONV layers and make them trainable\n",
        "teacher_resnet_50.trainable = True\n",
        "# print(\"Number of layers in the base model: \", len(student_base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "for layer in teacher_resnet_50.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "optimizer=tf.keras.optimizers.Adam(1e-5)\n",
        "teacher_model.compile(optimizer=optimizer,  # Very low learning rate\n",
        "              loss=None)\n",
        "\n",
        "teacher_model.summary()\n",
        "print(len(teacher_model.trainable_variables))\n",
        "\n",
        "# train the model again, this time fine-tuning *both* the final set\n",
        "# of CONV layers along with our set of FC layers\n",
        "\n",
        "# history_finetune = teacher_model.fit(train_dataset, epochs=25)\n",
        "NUM_EPOCHS = 25\n",
        "h1_finetune, h2_finetune = train_and_evaluate(teacher_model, compute_teacher_loss)"
      ],
      "metadata": {
        "id": "oNchUMGFu2-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_1 += h1_finetune\n",
        "f1_2 += h2_finetune"
      ],
      "metadata": {
        "id": "VYleBCvZrkks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.plot(f1_1, label='F1 Score: HP',linestyle='--', marker='o')\n",
        "plt.plot(f1_2, label='F1 Score: SSA',linestyle='--', marker='o')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.plot([initial_epoch,initial_epoch],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Testing Accuracy of Teacher Model')\n",
        "\n",
        "# plt.savefig('/content/images_mhist/teacher_train_acc2.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nTg9VlAFQrbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create student model -- use pre-trained MobileNetV2**"
      ],
      "metadata": {
        "id": "_JMGkRGSOHo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# student model\n",
        "def create_student():\n",
        "  input_size = (224,224,3)\n",
        "  student_base_model = tf.keras.applications.MobileNetV2(input_shape=input_size,\n",
        "                                                include_top=False,\n",
        "                                                weights='imagenet')\n",
        "\n",
        "  image_batch, label_batch = next(iter(train_dataset))\n",
        "  feature_batch = student_base_model(image_batch)\n",
        "  print(feature_batch.shape)\n",
        "\n",
        "  student_base_model.trainable = False\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "  feature_batch_average = global_average_layer(feature_batch)\n",
        "  prediction_layer = tf.keras.layers.Dense(2)\n",
        "  prediction_batch = prediction_layer(feature_batch_average)\n",
        "  print(prediction_batch.shape)\n",
        "\n",
        "  inputs = tf.keras.Input(shape=input_size)\n",
        "  x = student_base_model(inputs, training=False)\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  student_model = tf.keras.Model(inputs, outputs)\n",
        "  # student_model.summary()\n",
        "  student_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),loss=None)\n",
        "  return student_model, student_base_model\n",
        "\n"
      ],
      "metadata": {
        "id": "xz1QIN5YGgJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train and evaluate student model**"
      ],
      "metadata": {
        "id": "-vzfFGxkO3Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS= 10\n",
        "initial_epoch = NUM_EPOCHS\n",
        "DISTILLATION_TEMPERATURE = 4\n",
        "ALPHA = 0.5\n",
        "optimizer = tf.optimizers.Adam(learning_rate=1e-3)\n",
        "student_model, student_base_model = create_student()\n",
        "student_model.summary()\n",
        "# train and save student model\n",
        "# checkpoint_path = '/content/student_model.ckpt'\n",
        "# model_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                  save_weights_only=True,\n",
        "#                                                  verbose=1)\n",
        "student_f1_1, student_f1_2= train_and_evaluate(student_model,compute_student_loss_withoutKD)\n",
        "# matrix = student_model.fit(train_dataset,\n",
        "#                            epochs = NUM_EPOCHS,\n",
        "#                            callbacks=[model_callback])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IuDrP-uj6apC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.save('/content/student_model.h5') "
      ],
      "metadata": {
        "id": "KYtN1h4mAyNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tune student model "
      ],
      "metadata": {
        "id": "YZ1jwD0AO8EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# student_model,student_base_model = create_student()\n",
        "# student_model = load_model('/content/student_model.h5')"
      ],
      "metadata": {
        "id": "Fxzt0FQmDi_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune(model, base_model):\n",
        "  # unfreeze the final set of CONV layers and make them trainable\n",
        "  base_model.trainable = True\n",
        "  # print(\"Number of layers in the base model: \", len(student_base_model.layers))\n",
        "\n",
        "  # Fine-tune from this layer onwards\n",
        "  fine_tune_at = 100\n",
        "\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=1e-4)\n",
        "  model.compile(optimizer=optimizer, \n",
        "                loss = None,\n",
        "                # metrics=['acc'])\n",
        "                metrics = None)\n",
        "\n",
        "  # model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "FtJq0NOIJVRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS= 25\n",
        "ALPHA = 0.5\n",
        "DISTILLATION_TEMPERATURE = 4\n",
        "optimizer = tf.optimizers.Adam(learning_rate=1e-4)\n",
        "student_model = fine_tune(student_model, student_base_model)\n",
        "student_f1_1_fine, student_f1_2_fine = train_and_evaluate(student_model,compute_student_loss)\n"
      ],
      "metadata": {
        "id": "HcqGpIbPvW3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_1_student = student_f1_1 + student_f1_1_fine\n",
        "f1_2_student = student_f1_2 + student_f1_2_fine\n",
        "# print(f1_2_student)\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.plot(f1_1_student, label='F1 Score: HP',linestyle='--', marker='o')\n",
        "plt.plot(f1_2_student, label='F1 Score: SSA',linestyle='--', marker='o')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.plot([initial_epoch,initial_epoch],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Testing Accuracy of Student Model')\n",
        "\n",
        "# plt.savefig('/content/images_mhist/student_test_acc.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mn4s8Ujavs8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test accuracy vs. Tempreture curve**"
      ],
      "metadata": {
        "id": "V9lz7nNsPZ_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Temperatures = [1,2,4,16,32,64]\n",
        "ALPHA=0.5\n",
        "# student_accuracy_matrixes = []\n",
        "student_f1_scores_1 = []\n",
        "student_f1_scores_2 = []\n",
        "# latest = tf.train.latest_checkpoint(checkpoint_path)\n",
        "for t in Temperatures:\n",
        "  TEMPERATURE = t\n",
        "  tf.keras.backend.clear_session()\n",
        "  student_model,student_base_model = create_student()\n",
        "  student_model = load_model('/content/student_model.h5')\n",
        "  # fine tuning student model with different T\n",
        "  NUM_EPOCHS= 25\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=1e-4)\n",
        "  student_model = fine_tune(student_model, student_base_model)\n",
        "  f1_fine_1,f1_fine_2 = train_and_evaluate(student_model,compute_student_loss)\n",
        "  # student_accuracy_matrixes.append(matrix_fine.get('Student Accuracy').numpy())\n",
        "  f1_fine_1 = student_f1_1 + f1_fine_1\n",
        "  f1_fine_2 = student_f1_2 + f1_fine_2\n",
        "  student_f1_scores_1.append(f1_fine_1)\n",
        "  student_f1_scores_2.append(f1_fine_2)\n",
        "  "
      ],
      "metadata": {
        "id": "DKTwUndaPbej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(student_f1_scores_1)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(student_f1_scores_1[0],linestyle='--', marker='o', label='Temperature=1')\n",
        "plt.plot(student_f1_scores_1[1],linestyle='--', marker='o', label='Temperature=2')\n",
        "plt.plot(student_f1_scores_1[2],linestyle='--', marker='o', label='Temperature=4')\n",
        "plt.plot(student_f1_scores_1[3],linestyle='--', marker='o', label='Temperature=16')\n",
        "plt.plot(student_f1_scores_1[4],linestyle='--', marker='o', label='Temperature=32')\n",
        "plt.plot(student_f1_scores_1[5],linestyle='--', marker='o', label='Temperature=64')\n",
        "plt.ylim(0.7,0.9)\n",
        "plt.plot([initial_epoch,initial_epoch],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('F1 Score')\n",
        "\n",
        "plt.title('Student Model F1 Scores for class HP With Different Temperatures')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(student_f1_scores_2[0],linestyle='--', marker='o', label='Temperature=1')\n",
        "plt.plot(student_f1_scores_2[1],linestyle='--', marker='o', label='Temperature=2')\n",
        "plt.plot(student_f1_scores_2[2],linestyle='--', marker='o', label='Temperature=4')\n",
        "plt.plot(student_f1_scores_2[3],linestyle='--', marker='o', label='Temperature=16')\n",
        "plt.plot(student_f1_scores_2[4],linestyle='--', marker='o', label='Temperature=32')\n",
        "plt.plot(student_f1_scores_2[5],linestyle='--', marker='o', label='Temperature=64')\n",
        "plt.ylim(0,0.3)\n",
        "plt.plot([initial_epoch,initial_epoch],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('F1 Score')\n",
        "\n",
        "plt.title('Student Model F1 Scores for class SSA With Different Temperatures')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8o0cwbfnaRQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing the teacher and student model \n",
        "## (number of of parameters and FLOPs)"
      ],
      "metadata": {
        "id": "GwC6xrenPA61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-flops\n",
        "from keras_flops import get_flops"
      ],
      "metadata": {
        "id": "grjIrBaJD3QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare teacher and student model\n",
        "\n",
        "# count number of parameters of Teacher and student model\n",
        "teacher_model.summary() # Trainable params: \n",
        "student_model.summary()  # Trainable params:\n",
        "\n",
        "# calculate FLOPs of the teacher and student model\n",
        "teacher_flops = get_flops(teacher_model, batch_size=BATCH_SIZE)\n",
        "print(\"The number of FLOPs of the teacher model:\", teacher_flops)\n",
        "# 223623992512\n",
        "\n",
        "student_flops = get_flops(student_model, batch_size=BATCH_SIZE)\n",
        "print(\"The number of FLOPs of the student model:\", student_flops)\n",
        "# 19604230144"
      ],
      "metadata": {
        "id": "aZ8tKKvoDkJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train student from scratch**"
      ],
      "metadata": {
        "id": "Fb0HHw8fPPjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import train\n",
        "# student from scratch\n",
        "input_size = (224,224,3)\n",
        "NUM_EPOCHS = 10\n",
        "student_base_model = tf.keras.applications.MobileNetV2(input_shape=input_size,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = student_base_model(image_batch)\n",
        "\n",
        "\n",
        "student_base_model.trainable = False\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "prediction_layer = tf.keras.layers.Dense(2)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)\n",
        "\n",
        "inputs = tf.keras.Input(shape=input_size)\n",
        "x = student_base_model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "student_no_distillation = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "student_no_distillation.compile(optimizer=optimizer, \n",
        "                      # loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "                      )\n",
        "\n",
        "\n",
        "student_no_distillation.summary()\n",
        "# student_no_distillation.fit(train_dataset, epochs=epoch)\n",
        "no_KD_f1_1, no_KD_f1_2 = train_and_evaluate(student_no_distillation, compute_student_noKD_loss)"
      ],
      "metadata": {
        "id": "xCMR9cjzDLp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuining the no distillation student model\n",
        "student_base_model.trainable = True\n",
        "# print(\"Number of layers in the base model: \", len(student_base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "for layer in student_base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable = False\n",
        "\n",
        "optimizer=tf.keras.optimizers.Adam(1e-4)\n",
        "NUM_EPOCHS = 25\n",
        "student_no_distillation.compile(optimizer=optimizer)\n",
        "\n",
        "student_no_distillation.summary()\n",
        "# student_no_distillation.fit(train_dataset, epochs=epoch)\n",
        "# student_base_model.summary()\n",
        "no_KD_f1_1_fine, no_KD_f1_2_fine = train_and_evaluate(student_no_distillation, compute_student_noKD_loss)\n"
      ],
      "metadata": {
        "id": "_n53_3bDGKVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_student_no_KD = no_KD_f1_1 + no_KD_f1_1_fine\n",
        "f2_student_no_KD = no_KD_f1_2 + no_KD_f1_2_fine\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "initial_epoch=10\n",
        "plt.plot(f1_student_no_KD, label='F1 Score: HP',linestyle='--', marker='o')\n",
        "plt.plot(f2_student_no_KD, label='F1 Score: SSA',linestyle='--', marker='o')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.plot([initial_epoch,initial_epoch],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Testing Accuracy of Student Model without Knowledge Distillation')\n",
        "\n",
        "# plt.savefig('/content/images_mhist/student_test_acc.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iq65Sg0a2ena"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare Teacher vs Student vs Student-No-Distillation**"
      ],
      "metadata": {
        "id": "BTyAGpUL3JxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.ylim(0.4,0.9)\n",
        "plt.plot(f1_1, label='Teacher',linestyle='--', marker='o')\n",
        "plt.plot(f1_1_student, label='Student',linestyle='--', marker='o')\n",
        "plt.plot(f1_student_no_KD, label='Student From Scratch',linestyle='--', marker='o')\n",
        "\n",
        "plt.plot([initial_epoch,initial_epoch],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower left')\n",
        "plt.ylabel('F1 Score')\n",
        "\n",
        "plt.title('F1 Scores for class HP')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.ylim(0,0.7)\n",
        "plt.plot(f1_2, label='Teacher',linestyle='--', marker='o')\n",
        "plt.plot(f1_2_student, label='Student',linestyle='--', marker='o')\n",
        "plt.plot(f2_student_no_KD, label='Student From Scratch',linestyle='--', marker='o')\n",
        "plt.plot([initial_epoch,initial_epoch],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper left')\n",
        "plt.ylabel('F1 Score')\n",
        "\n",
        "plt.title('F1 Scores for class SSA')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cOYtYFns3HWQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}